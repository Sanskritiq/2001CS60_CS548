{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "import pickle\n",
    "from os import path\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from FlowerPollinationAlgorithm import FlowerPollinationAlgorithm\n",
    "import time\n",
    "\n",
    "fpa = FlowerPollinationAlgorithm(lb=0, ub=1, thres=0.5, beta=1.5, P=0.8, max_iter=100)\n",
    "\n",
    "class FeatureSelection:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def read_data(self, train_file, test_file):\n",
    "        self.train_data = pd.read_csv(train_file, sep=',', encoding='utf-8')\n",
    "        self.test_data = pd.read_csv(test_file, sep=',', encoding='utf-8')\n",
    "\n",
    "    def split_data(self):\n",
    "        self.X_train = self.train_data.drop(columns=['label'], axis=1)\n",
    "        self.y_train = self.train_data['label']\n",
    "        self.X_test = self.test_data.drop(columns=['label'], axis=1)\n",
    "        self.y_test = self.test_data['label']\n",
    "        self.X_t, _, self.y_t, _ = train_test_split(self.X_train, self.y_train, train_size=0.01, random_state=7)\n",
    "\n",
    "    def perform_feature_selection(self):\n",
    "        feat = np.asarray(self.X_t)\n",
    "        label = np.asarray(self.y_t)\n",
    "        print(feat.shape, label.shape)\n",
    "\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(feat, label, test_size=0.3, stratify=label)\n",
    "        print(xtrain.shape, ytrain.shape, xtest.shape, ytest.shape)\n",
    "        fold = {'xt': xtrain, 'yt': ytrain, 'xv': xtest, 'yv': ytest}\n",
    "\n",
    "        k = 5   # k-value in KNN\n",
    "        N = 10  # number of chromosomes\n",
    "        T = 100 # maximum number of generations\n",
    "        P = 0.8 # switch probability\n",
    "\n",
    "        opts = {'k': k, 'fold': fold, 'N': N, 'T': T, 'P': P}\n",
    "\n",
    "        start_time = time.time()\n",
    "        # fmdl = jfs(feat, label, opts)\n",
    "        # fmdl = fpa.flower_pollination(xtrain, xtest, ytrain, ytest, opts)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # self.selected_features = fmdl['sf']\n",
    "        self.execution_time = end_time - start_time\n",
    "\n",
    "    def write_feature_file(self):\n",
    "        feature_name = self.filename + \"_FPA_feature.csv\"\n",
    "        with open(feature_name, 'w') as file:\n",
    "            file.write(\"optimization,execution time of optimzier,no of feature selected,selected feature\\n\")\n",
    "            file.write(\"FPA,\" + str(self.execution_time) + \",\" + str(len(self.selected_features)) + \",\\\"\")\n",
    "            column_headers = list(self.X_train.columns.values)\n",
    "            for i in self.selected_features:\n",
    "                file.write(column_headers[i] + \",\")\n",
    "            file.write(\"\\\"\\n\")\n",
    "\n",
    "    def select_features(self):\n",
    "        feature_df = pd.read_csv(self.filename + \"_FPA_feature.csv\", sep=',', encoding='utf-8')\n",
    "        selected_feature = feature_df.iat[0, 3]\n",
    "        selected_feature = selected_feature[0:-1]\n",
    "        return list(selected_feature.split(\",\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    @staticmethod\n",
    "    def preprocess_data(X_train, X_test, selected_features):\n",
    "        X_train = X_train[selected_features]\n",
    "        X_test = X_test[selected_features]\n",
    "        return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"NF-BOT-IOT\"\n",
    "feature_selector = FeatureSelection(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5020, 10) (5020,)\n",
      "(3514, 10) (3514,) (1506, 10) (1506,)\n"
     ]
    }
   ],
   "source": [
    "feature_selector.read_data('NF-BOT-IOT_train_preprocessed.csv', 'NF-BOT-IOT_test_preprocessed.csv')\n",
    "feature_selector.split_data()\n",
    "feature_selector.perform_feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
